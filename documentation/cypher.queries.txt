------------------------------------------------------------------------------------------------------------------
//Load Users, Ip Addresses and connect Users with IP Addresses

// Constraints
CREATE CONSTRAINT user_id IF NOT EXISTS FOR (u:User) REQUIRE u.userId IS UNIQUE;
CREATE CONSTRAINT ip_address IF NOT EXISTS FOR (i:IpAddress) REQUIRE i.address IS UNIQUE;

// Data load
LOAD CSV WITH HEADERS FROM "https://gist.githubusercontent.com/chintan196/6b33019341bdcb6ed4d712cc94b84fc6/raw/2513454dd72b70d3122fd0a15777fc9842bbba89/Users.csv" AS row
MERGE (u:User { userId: toInteger(row.userId) })
ON CREATE SET 
u.firstName= row.firstName,
u.lastName= row.lastName,
u.gender= row.gender,
u.email= row.email,
u.phone= row.phone,
u.state= row.state,
u.country= row.country
WITH u, row
MERGE (ip:IpAddress { address: row.ipAddress })
MERGE (u)-[:USES]->(ip)
RETURN u, ip

------------------------------------------------------------------------------------------------------------------
// Load Movies, Genres and link them

// Constraints
CREATE CONSTRAINT genre_name IF NOT EXISTS FOR (g:Genre) REQUIRE g.name IS UNIQUE;
CREATE CONSTRAINT movie_id IF NOT EXISTS FOR (m:Movie) REQUIRE m.movieId IS UNIQUE;
CREATE CONSTRAINT movie_name IF NOT EXISTS FOR (m:Movie) REQUIRE m.name IS UNIQUE;

//Load Data
:auto USING PERIODIC COMMIT 500
LOAD CSV WITH HEADERS FROM 
"https://gist.githubusercontent.com/chintan196/6b33019341bdcb6ed4d712cc94b84fc6/raw/2513454dd72b70d3122fd0a15777fc9842bbba89/Movies.csv" AS row
MERGE ( m:Movie { movieId: toInteger(row.movieId) })
ON CREATE SET 
m.name= row.name,
m.year= toInteger(row.year)
WITH m, row
MERGE (g:Genre { name: row.genre } )
MERGE (m)-[:HAS]->(g) RETURN m, g;

------------------------------------------------------------------------------------------------------------------
//Load Watch Events Relationships - Execute this after loading user and movies
LOAD CSV WITH HEADERS FROM "https://gist.githubusercontent.com/chintan196/6b33019341bdcb6ed4d712cc94b84fc6/raw/2513454dd72b70d3122fd0a15777fc9842bbba89/WatchEvent.csv" AS row
MATCH (u:User {userId: toInteger(row.userId)})
MATCH (m:Movie {movieId: toInteger(row.movieId)})  
MERGE (u)-[w:WATCHED]->(m) ON CREATE SET w.watchCount = toInteger(row.watchCount)
RETURN u, m;
------------------------------------------------------------------------------------------------------------------
// Query users who have watched movie "The Boss Baby: Family Business"
MATCH (u:User)-->(m:Movie {name: "The Boss Baby: Family Business"}) RETURN u,m LIMIT 5
------------------------------------------------------------------------------------------------------------------
// Show users from "New York" and movies watched by them
MATCH (u:User {state: "New York"} )-[:WATCHED]->(m)  RETURN u, m LIMIT 50
------------------------------------------------------------------------------------------------------------------
// Show trending genres in Texas
MATCH (u:User {state: "Texas"} )-[:WATCHED]->(m)-[:HAS]->(g)
return g.name, count(g) order by count(g) desc
------------------------------------------------------------------------------------------------------------------
//Users who have similar names
// These are users who have same/similar names but different (redundant) accounts due to typos or abbreviations used for some instance
MATCH (a:User)
MATCH (b:User)
WHERE a.firstName + a.lastName <> b.firstName + b.lastName
WITH a, b, a.firstName + a.lastName AS norm1, b.firstName + b.lastName AS norm2
WITH 
toInteger(apoc.text.jaroWinklerDistance(norm1, norm2) * 100) AS nameSimilarity,
toInteger(apoc.text.jaroWinklerDistance(a.email, b.email) * 100) AS emailSimilarity,
toInteger(apoc.text.jaroWinklerDistance(a.phone, b.phone) * 100) AS phoneSimilarity, a, b
WITH a, b, toInteger((nameSimilarity + emailSimilarity + phoneSimilarity)/3) as similarity WHERE similarity >= 90
RETURN a.firstName + a.lastName AS p1, b.firstName + b.lastName AS p2, a.email, b.email,  similarity
------------------------------------------------------------------------------------------------------------------
//Users belonging to same family
//Find users who have similar last names and live in same state, and connected using same IP address, that means they are either same users with redundant account or belong to the same family
MATCH (a:User)-->(:IpAddress)<--(b:User)
WHERE a.lastName =  b.lastName AND a.state = b.state AND a.country = b.country
WITH a.lastName as familyName, collect(distinct b.firstName + ' '  + b.lastName) as members, count(distinct b) as memberCount
RETURN familyName, memberCount, members
------------------------------------------------------------------------------------------------------------------
//Create Family Nodes for each family and connect members
MATCH (a:User)-->(:IpAddress)<--(b:User)
WHERE a.lastName =  b.lastName AND a.state = b.state AND a.country = b.country
WITH a.lastName as familyName, collect(distinct b) as familyMembers, count(distinct b) as totalMembers
MERGE (a:Family {name: familyName})
WITH a,familyMembers
UNWIND  familyMembers as member
MERGE (member)-[:BELONGS_TO]->(a)
RETURN a, member

//Show all families
MATCH (f:Family)<--(u:User) RETURN f, u LIMIT 200
------------------------------------------------------------------------------------------------------------------
//Providing recommendation to the member bease on his account\family members history
//Check other genres preferred by account members and suggest top 5 movies from most watched genres
MATCH (user:User {firstName: "Vilma", lastName: "De Mars"})
MATCH (user)-[:BELONGS_TO]->(f)<-[:BELONGS_TO]-(otherMember)
MATCH (otherMember)-[:WATCHED]->(m1)-[:HAS]->(g:Genre)<-[:HAS]-(m2)
WITH g.name as genre, count(distinct m2) as totalMovies, collect(m2.name) as movies
RETURN genre, totalMovies, movies[0..5] as topFiveMovies ORDER BY totalMovies DESC LIMIT 50 
------------------------------------------------------------------------------------------------------------------

//Find users based on their movie watching preferences using Node Similarity algorithm
//Node Similarity-Create Graph
//CREATE GRAPH FOR Node Similarity
CALL gds.graph.create(
    'similarityGraph',
    ['User', 'Movie'],
    {
        WATCHED: {
            type: 'WATCHED',
            properties: {
                strength: {
                    property: 'watchCount',
                    defaultValue: 1
                }
            }
        }
    }
);

//Node Similarity - Graph Memory Estimate
//The following will estimate the memory requirements for running the algorithm
CALL gds.nodeSimilarity.write.estimate('similarityGraph', {
  writeRelationshipType: 'SIMILAR',
  writeProperty: 'score'
})
YIELD nodeCount, relationshipCount, bytesMin, bytesMax, requiredMemory
------------------------------------------------------------------------------------------------------------------
//Node Similarity - Execute algorithm and show results
//The following will run the algorithm, and stream results
CALL gds.nodeSimilarity.stream('similarityGraph')
YIELD node1, node2, similarity
WITH gds.util.asNode(node1) AS Person1, gds.util.asNode(node2) AS Person2, similarity
RETURN 
Person1.firstName + ' ' +  Person1.lastName as p1,
Person2.firstName  + ' ' +   Person2.lastName as p2, similarity ORDER BY similarity DESC
------------------------------------------------------------------------------------------------------------------
//Get recommendations for a user based on similarity. For a user, fetch recommendations based on other similar users' preferences
CALL gds.nodeSimilarity.stream('similarityGraph')
YIELD node1, node2, similarity
WITH gds.util.asNode(node1) AS Person1, gds.util.asNode(node2) AS Person2, similarity
WHERE Person1.firstName = 'Paulie' AND Person1.lastName = 'Imesson'
MATCH (Person2)-[w:WATCHED]->(m) WHERE NOT exists((Person1)-->(m))
WITH  DISTINCT m as movies, SUM(w.watchCount) as watchCount
RETURN movies order by watchCount
------------------------------------------------------------------------------------------------------------------
//Find similar users by genre preference using Pearson similarity function
//Here we are finding the users who have similar preferences as Lanette Laughtisse
//We are comparing the similarities based on the movies they have watched from similar genre
MATCH (p1:User {firstName:"Lanette", lastName:"Laughtisse"} )-[:WATCHED]->(m:Movie)
MATCH (m)-[:HAS]->(g1:Genre) 
WITH p1, g1, count(m) as movieCount1
WITH p1, gds.alpha.similarity.asVector(g1, movieCount1) AS p1Vector
MATCH (p2:User)-[:WATCHED]->(m2:Movie)
MATCH (m2)-[:HAS]->(g1:Genre) WHERE p2 <> p1
WITH p1, g1, p1Vector, p2, count(m2) as movieCount2
WITH p1, p2, p1Vector, gds.alpha.similarity.asVector(g1, movieCount2) AS p2Vector
WHERE size(apoc.coll.intersection([v in p1Vector | v.category], [v in p2Vector | v.category])) > 3
WITH 
p1.firstName + ' '  + p1.lastName  AS currentUser,
p2.firstName + ' ' + p2.lastName  AS similarUser,
gds.alpha.similarity.pearson(p1Vector, p2Vector, {vectorType: "maps"}) AS similarity
WHERE similarity > 0.9
RETURN currentUser,similarUser, similarity
       ORDER BY similarity DESC
LIMIT 100
------------------------------------------------------------------------------------------------------------------
//Get recommendations for a user using similar order users' preferenes by fetching similar users using Pearson Similarity function
MATCH (p1:User {firstName:"Lanette", lastName:"Laughtisse"} )-[:WATCHED]->(m:Movie)
MATCH (m)-[:HAS]->(g1:Genre) 
WITH p1, g1, count(m) as movieCount1
WITH p1, gds.alpha.similarity.asVector(g1, movieCount1) AS p1Vector
MATCH (p2:User)-[:WATCHED]->(m2:Movie)
MATCH (m2)-[:HAS]->(g1:Genre) WHERE p2 <> p1
WITH p1, g1, p1Vector, p2, count(m2) as movieCount2
WITH p1, p2, p1Vector, gds.alpha.similarity.asVector(g1, movieCount2) AS p2Vector
WHERE size(apoc.coll.intersection([v in p1Vector | v.category], [v in p2Vector | v.category])) > 3
WITH 
p1 AS currentUser,
p2 AS similarUser,
gds.alpha.similarity.pearson(p1Vector, p2Vector, {vectorType: "maps"}) AS similarity
WHERE similarity > 0.9
MATCH (similarUser)-[w:WATCHED]->(m) 
WITH  DISTINCT m as movies, SUM(w.watchCount) as watchCount
RETURN movies order by watchCount
------------------------------------------------------------------------------------------------------------------
